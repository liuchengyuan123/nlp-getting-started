{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./data/train.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['id'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7608</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Two giant cranes holding a bridge collapse int...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7609</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@aria_ahrary @TheTawniest The out of control w...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7610</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M1.94 [01:04 UTC]?5km S of Volcano Hawaii. htt...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7611</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Police investigating after an e-bike collided ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7612</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The Latest: More Homes Razed by Northern Calif...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7613 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     keyword location                                               text  \\\n",
       "0        NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1        NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2        NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3        NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4        NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "...      ...      ...                                                ...   \n",
       "7608     NaN      NaN  Two giant cranes holding a bridge collapse int...   \n",
       "7609     NaN      NaN  @aria_ahrary @TheTawniest The out of control w...   \n",
       "7610     NaN      NaN  M1.94 [01:04 UTC]?5km S of Volcano Hawaii. htt...   \n",
       "7611     NaN      NaN  Police investigating after an e-bike collided ...   \n",
       "7612     NaN      NaN  The Latest: More Homes Razed by Northern Calif...   \n",
       "\n",
       "      target  \n",
       "0          1  \n",
       "1          1  \n",
       "2          1  \n",
       "3          1  \n",
       "4          1  \n",
       "...      ...  \n",
       "7608       1  \n",
       "7609       1  \n",
       "7610       1  \n",
       "7611       1  \n",
       "7612       1  \n",
       "\n",
       "[7613 rows x 4 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keyword</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>ablaze</td>\n",
       "      <td>Revel in yours wmv videos by means of mac fare...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>61</td>\n",
       "      <td>ablaze</td>\n",
       "      <td>Progressive greetings!\\n\\nIn about a month stu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>62</td>\n",
       "      <td>ablaze</td>\n",
       "      <td>Rene Ablaze &amp;amp; Jacinta - Secret 2k13 (Falle...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>63</td>\n",
       "      <td>ablaze</td>\n",
       "      <td>@Navista7 Steve these fires out here are somet...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64</td>\n",
       "      <td>ablaze</td>\n",
       "      <td>#NowPlaying: Rene Ablaze &amp;amp; Ian Buff - Magn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65</td>\n",
       "      <td>ablaze</td>\n",
       "      <td>@nxwestmidlands huge fire at Wholesale markets...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>66</td>\n",
       "      <td>ablaze</td>\n",
       "      <td>@ablaze what time does your talk go until? I d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>67</td>\n",
       "      <td>accident</td>\n",
       "      <td>'I can't have kids cuz I got in a bicycle acci...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>68</td>\n",
       "      <td>accident</td>\n",
       "      <td>Accident on I-24 W #NashvilleTraffic. Traffic ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69</td>\n",
       "      <td>accident</td>\n",
       "      <td>Accident center lane blocked in #SantaClara on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>accident</td>\n",
       "      <td>http://t.co/GKYe6gjTk5 Had a #personalinjury a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     keyword                                               text\n",
       "60    ablaze  Revel in yours wmv videos by means of mac fare...\n",
       "61    ablaze  Progressive greetings!\\n\\nIn about a month stu...\n",
       "62    ablaze  Rene Ablaze &amp; Jacinta - Secret 2k13 (Falle...\n",
       "63    ablaze  @Navista7 Steve these fires out here are somet...\n",
       "64    ablaze  #NowPlaying: Rene Ablaze &amp; Ian Buff - Magn...\n",
       "65    ablaze  @nxwestmidlands huge fire at Wholesale markets...\n",
       "66    ablaze  @ablaze what time does your talk go until? I d...\n",
       "67  accident  'I can't have kids cuz I got in a bicycle acci...\n",
       "68  accident  Accident on I-24 W #NashvilleTraffic. Traffic ...\n",
       "69  accident  Accident center lane blocked in #SantaClara on...\n",
       "70  accident  http://t.co/GKYe6gjTk5 Had a #personalinjury a..."
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[60:70, ['keyword', 'text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_pretrained_bert import BertModel, BertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = tokenizer.convert_tokens_to_ids(['hello', 'world'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "bertmodel = BertModel.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7592, 2088])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.tensor(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([tensor([[[ 0.2342,  0.4187, -0.3626,  ..., -0.1554, -0.3838, -0.0074],\n",
       "           [ 0.6342,  1.1416,  1.0819,  ..., -0.2009, -0.0843, -0.5864]]],\n",
       "         grad_fn=<AddBackward0>),\n",
       "  tensor([[[ 0.4153,  0.0188, -0.2105,  ...,  0.0493, -0.1618, -0.1698],\n",
       "           [ 0.7684,  1.9880,  1.1199,  ..., -0.7275, -0.1263, -0.7111]]],\n",
       "         grad_fn=<AddBackward0>),\n",
       "  tensor([[[-0.2007,  0.2708,  0.0075,  ...,  0.2475, -0.0257,  0.0119],\n",
       "           [ 0.7127,  2.0042,  0.7233,  ...,  0.0373, -0.2503, -0.0933]]],\n",
       "         grad_fn=<AddBackward0>),\n",
       "  tensor([[[-0.2711, -0.0598, -0.1825,  ..., -0.5826, -0.1346,  0.1213],\n",
       "           [ 0.5141,  1.9654,  0.3506,  ..., -0.3855, -0.2491,  0.3105]]],\n",
       "         grad_fn=<AddBackward0>),\n",
       "  tensor([[[-0.0699,  0.9620, -0.2964,  ..., -1.1470, -0.2573,  0.3411],\n",
       "           [ 0.4215,  2.2552,  0.5336,  ..., -0.6305, -0.5313, -0.3380]]],\n",
       "         grad_fn=<AddBackward0>),\n",
       "  tensor([[[-0.1245,  0.5391,  0.3720,  ...,  0.0806, -0.0871,  0.3962],\n",
       "           [-0.0932,  1.8256,  1.2071,  ...,  0.6775,  0.0399, -0.5869]]],\n",
       "         grad_fn=<AddBackward0>),\n",
       "  tensor([[[-0.2059,  0.5781,  0.8945,  ...,  0.0791,  0.1792,  0.6409],\n",
       "           [ 0.1653,  1.7680,  1.6960,  ...,  0.5004,  0.6034, -0.5379]]],\n",
       "         grad_fn=<AddBackward0>),\n",
       "  tensor([[[-0.6890,  0.5946,  1.5741,  ...,  0.0973,  0.4794,  0.8841],\n",
       "           [-0.4214,  1.5107,  1.8070,  ...,  0.0670,  0.0047, -0.2820]]],\n",
       "         grad_fn=<AddBackward0>),\n",
       "  tensor([[[-0.7868,  0.7901,  0.7802,  ..., -0.8891,  0.5660,  1.5884],\n",
       "           [-0.5842,  1.4955,  0.7436,  ..., -0.5942, -0.0941, -0.1914]]],\n",
       "         grad_fn=<AddBackward0>),\n",
       "  tensor([[[-0.5774,  0.5289, -0.2866,  ..., -0.2989, -0.0064,  1.4388],\n",
       "           [ 0.0188,  1.2377, -0.0588,  ...,  0.0245,  0.0027, -0.3479]]],\n",
       "         grad_fn=<AddBackward0>),\n",
       "  tensor([[[-0.4055,  0.9694, -0.4690,  ..., -0.4806, -0.3136,  1.4906],\n",
       "           [-0.2957,  1.7790, -0.2675,  ...,  0.3516,  0.3588, -0.6385]]],\n",
       "         grad_fn=<AddBackward0>),\n",
       "  tensor([[[-0.5630,  1.2786,  0.1610,  ..., -0.3878, -0.3680,  0.8207],\n",
       "           [-0.1283,  1.3610,  0.3514,  ...,  0.1955,  0.1595, -0.1046]]],\n",
       "         grad_fn=<AddBackward0>)],\n",
       " tensor([[-0.6735,  0.0089,  0.2485,  0.6397,  0.2173, -0.2773,  0.6226,  0.0447,\n",
       "           0.4561, -0.9797, -0.0693,  0.0523,  0.9505, -0.6231,  0.7936, -0.5414,\n",
       "          -0.5715, -0.2725,  0.2525, -0.3926,  0.7343,  0.9721,  0.2091,  0.2660,\n",
       "           0.0509, -0.1025, -0.6045,  0.8590,  0.8225,  0.7209, -0.5789,  0.0788,\n",
       "          -0.9754, -0.3175, -0.4357, -0.9613,  0.0869, -0.6201, -0.3672, -0.0632,\n",
       "          -0.9293,  0.4494,  0.9697, -0.1579,  0.7711, -0.3308, -0.9782,  0.2407,\n",
       "          -0.6782, -0.8196,  0.2936, -0.7061,  0.1875,  0.2729,  0.3882, -0.1458,\n",
       "          -0.0393,  0.1653, -0.1285, -0.3013, -0.3172,  0.2389, -0.0622, -0.7936,\n",
       "          -0.2247, -0.7644, -0.1695, -0.2540, -0.0976, -0.0389,  0.4664,  0.1941,\n",
       "           0.7247, -0.8077, -0.6897,  0.2753, -0.1286,  0.9998, -0.0491, -0.9606,\n",
       "          -0.0833, -0.6726,  0.0911,  0.6861, -0.7378, -0.9981,  0.0814, -0.2867,\n",
       "          -0.9516,  0.2070,  0.5144, -0.0243, -0.0135, -0.0039, -0.1443, -0.5598,\n",
       "          -0.3170,  0.0584, -0.1685, -0.2757,  0.0676, -0.2896, -0.1441, -0.0257,\n",
       "           0.1875, -0.0909, -0.3923, -0.5631, -0.0667,  0.3686,  0.2030, -0.2192,\n",
       "           0.2541, -0.7671,  0.5106, -0.1591, -0.9351, -0.0397, -0.9349,  0.7227,\n",
       "          -0.6078, -0.4670,  0.8298, -0.3757,  0.1485, -0.2437,  0.7445, -0.9999,\n",
       "          -0.3167, -0.8358,  0.6218, -0.0674, -0.9463, -0.8905,  0.1292,  0.8981,\n",
       "           0.0887,  0.9810, -0.2426,  0.8767,  0.6488,  0.0557, -0.2184, -0.1255,\n",
       "           0.6939,  0.5135, -0.8237,  0.1534, -0.1013, -0.4447, -0.4583, -0.3379,\n",
       "          -0.0215, -0.7502, -0.3087,  0.8491,  0.3098,  0.7945,  0.6839,  0.1830,\n",
       "          -0.6226,  0.7850,  0.5955,  0.1958,  0.2735,  0.2188, -0.4153,  0.3593,\n",
       "          -0.7835,  0.2470,  0.1991, -0.3490,  0.1882, -0.9437, -0.2562,  0.3155,\n",
       "           0.9276,  0.4543,  0.3659, -0.5348, -0.3019, -0.1902, -0.8676,  0.9539,\n",
       "          -0.0164,  0.0296, -0.8129, -0.7528, -0.8796, -0.2551,  0.5838,  0.0667,\n",
       "          -0.8076, -0.0435, -0.3973, -0.2216, -0.6602,  0.6358, -0.3505, -0.4703,\n",
       "          -0.3250,  0.8827,  0.7537,  0.8058, -0.1413,  0.3736, -0.7269, -0.2573,\n",
       "           0.3110,  0.0779,  0.1122,  0.9495, -0.6341, -0.1368, -0.5605, -0.9260,\n",
       "           0.2679, -0.4227,  0.1457, -0.7490,  0.3353, -0.3657, -0.7397,  0.3438,\n",
       "          -0.6204, -0.6837,  0.1998, -0.5472,  0.3328, -0.3231,  0.9627, -0.1316,\n",
       "          -0.4740,  0.5014,  0.9194,  0.0436, -0.8913,  0.6637, -0.2854,  0.3723,\n",
       "          -0.3863,  0.9308,  0.2197,  0.2022, -0.8053,  0.0342, -0.4833,  0.6245,\n",
       "          -0.2570, -0.7080, -0.5805, -0.0492,  0.1492,  0.6426, -0.4253,  0.7292,\n",
       "          -0.9829, -0.9036, -0.9103,  0.4364, -0.9706,  0.6782,  0.1393,  0.8423,\n",
       "          -0.5667, -0.4949, -0.9483,  0.5946,  0.0749,  0.7495, -0.6963, -0.7801,\n",
       "           0.1041, -0.9375,  0.0842, -0.0751,  0.7259,  0.1410, -0.8151,  0.2129,\n",
       "           0.5580,  0.0980,  0.7758,  0.8296,  0.9951,  0.9605,  0.6975,  0.2850,\n",
       "          -0.9387, -0.7257,  0.9738, -0.5797, -0.9987, -0.8594, -0.6944,  0.5594,\n",
       "          -0.9999, -0.1475, -0.1631, -0.8436, -0.5734,  0.9074,  0.7515, -0.9997,\n",
       "           0.5958,  0.6987, -0.0432,  0.0684, -0.5659,  0.9331,  0.1469,  0.6653,\n",
       "          -0.1158,  0.2983, -0.1772, -0.7173,  0.0515, -0.2127,  0.7268,  0.1457,\n",
       "          -0.3242, -0.6944,  0.7678, -0.2458,  0.2553, -0.8843, -0.3066,  0.0729,\n",
       "           0.5835,  0.3369,  0.1270, -0.6336,  0.2158, -0.2851,  0.1462,  0.2044,\n",
       "          -0.6382, -0.2996,  0.5342, -0.6057,  0.3967, -0.9411,  0.8500,  0.0080,\n",
       "          -0.4416,  0.9997,  0.9200, -0.7815,  0.3778,  0.0662, -0.7986,  0.9991,\n",
       "           0.0607, -0.9552, -0.1724, -0.3401, -0.3111, -0.2409,  0.9568, -0.0655,\n",
       "           0.0540, -0.5787,  0.9535, -0.9619,  0.2344, -0.4481, -0.9017,  0.8890,\n",
       "           0.9077, -0.6135, -0.7926,  0.0746,  0.5780,  0.1833, -0.4848,  0.4242,\n",
       "           0.7176, -0.2916,  0.7223, -0.6832, -0.0439,  0.2784,  0.2486,  0.6292,\n",
       "           0.4142,  0.3183, -0.3081, -0.1736, -0.2552, -0.9599, -0.6784,  0.5089,\n",
       "           0.9994,  0.0334,  0.8802,  0.6029, -0.3528, -0.0023,  0.3078,  0.3362,\n",
       "          -0.1642, -0.7580,  0.1189, -0.5442, -0.9714,  0.5672,  0.1228,  0.1474,\n",
       "           0.9734,  0.2372,  0.1342, -0.3987,  0.0426,  0.5687,  0.4191, -0.5727,\n",
       "           0.9548, -0.2126,  0.1310,  0.5719,  0.5907, -0.3583, -0.3346, -0.1811,\n",
       "          -0.9621,  0.0226, -0.8251,  0.9426, -0.8169,  0.3076,  0.2078,  0.7497,\n",
       "           0.9996, -0.9770,  0.5040, -0.0664,  0.8011, -0.7452, -0.1676, -0.0901,\n",
       "          -0.1904,  0.5354, -0.1871,  0.0702, -0.9144, -0.6475,  0.0175, -0.7988,\n",
       "          -0.9294,  0.6527,  0.4346,  0.2137, -0.7964, -0.3749, -0.5997,  0.1749,\n",
       "          -0.4557, -0.9003,  0.6755, -0.2793, -0.0064, -0.4101,  0.0960, -0.5464,\n",
       "           0.6004, -0.7275, -0.0374, -0.2437, -0.7808,  0.6858, -0.5033,  0.3041,\n",
       "          -0.1891,  0.9998, -0.3954,  0.0492,  0.5641,  0.3769, -0.1072,  0.3331,\n",
       "           0.0803,  0.1297,  0.7425,  0.6686, -0.5768, -0.3669,  0.4973,  0.7852,\n",
       "          -0.5498,  0.8367,  0.6041, -0.0675, -0.0582,  0.1703,  0.8217, -0.4288,\n",
       "          -0.4120, -0.3582, -0.2027, -0.2264, -0.5866,  0.9990,  0.0498,  0.6124,\n",
       "          -0.9608, -0.5101, -0.5970,  0.9937,  0.7808, -0.5923,  0.1998,  0.1414,\n",
       "          -0.0786,  0.4772, -0.1914, -0.2331,  0.2892,  0.2253,  0.8783, -0.1995,\n",
       "          -0.9679, -0.8688,  0.1346, -0.8857,  0.9610, -0.2108, -0.1931, -0.3822,\n",
       "           0.0058,  0.5532,  0.1376, -0.8569,  0.0535,  0.2337,  0.9104,  0.4558,\n",
       "           0.0082, -0.7285, -0.5339,  0.4350,  0.3320, -0.8934,  0.9499, -0.6751,\n",
       "          -0.1496,  0.9983,  0.4185, -0.6285,  0.2275, -0.2720,  0.0766, -0.7565,\n",
       "           0.3978, -0.9079, -0.1788, -0.2679,  0.3248, -0.1953, -0.6992,  0.4614,\n",
       "           0.2328, -0.0599, -0.1034, -0.3608,  0.0193,  0.4678, -0.2198, -0.0318,\n",
       "          -0.0675, -0.0212, -0.7483,  0.0187, -0.1094, -0.9766,  0.2566, -0.9998,\n",
       "           0.1296, -0.6198, -0.2471,  0.8179,  0.5832, -0.0868, -0.8141,  0.7647,\n",
       "           0.8751,  0.6733, -0.2924,  0.4752, -0.7854,  0.2247, -0.3443,  0.2087,\n",
       "           0.5218,  0.4070, -0.2174,  0.9998,  0.0026, -0.5366, -0.6450,  0.0378,\n",
       "          -0.4242,  0.9987, -0.5411, -0.8023,  0.2724, -0.3240, -0.7038,  0.1972,\n",
       "           0.2667, -0.5965, -0.6776,  0.7656,  0.7178,  0.0080,  0.6176, -0.3773,\n",
       "          -0.3563,  0.0732, -0.3111,  0.9518,  0.9156,  0.8373, -0.5714, -0.7109,\n",
       "           0.8908,  0.3264,  0.5529,  0.0572,  0.9989,  0.4310, -0.8904, -0.2723,\n",
       "          -0.8346, -0.1989, -0.7307,  0.0828,  0.4081,  0.8329, -0.4058,  0.9421,\n",
       "           0.1519, -0.0151,  0.2320,  0.5901,  0.0347, -0.8648, -0.9326, -0.9592,\n",
       "           0.3148, -0.3588, -0.0118,  0.3469,  0.3271,  0.3300, -0.0500, -0.9995,\n",
       "           0.7688,  0.2498, -0.5896,  0.9002,  0.1424,  0.5235,  0.2305, -0.9331,\n",
       "          -0.7442, -0.3736, -0.3529,  0.8083,  0.4525,  0.8040,  0.0694, -0.0892,\n",
       "          -0.6331, -0.0898, -0.8046, -0.9457,  0.0979,  0.7683, -0.3559,  0.9272,\n",
       "          -0.6823, -0.1717,  0.6962,  0.3617, -0.2126,  0.6069,  0.6171,  0.1896,\n",
       "           0.6559,  0.7844,  0.8083,  0.9556,  0.5175,  0.5582,  0.8020,  0.4026,\n",
       "           0.9596, -0.9104,  0.2813,  0.6412, -0.2227,  0.1510, -0.2507, -0.2130,\n",
       "           0.9726, -0.0325,  0.7838, -0.4449,  0.0660, -0.2229, -0.2056, -0.8375,\n",
       "          -0.1900, -0.0581,  0.2325,  0.9106,  0.4975, -0.1041, -0.3210, -0.2422,\n",
       "           0.7078, -0.9230,  0.4186, -0.3156,  0.7585,  0.5921,  0.0040,  0.9772,\n",
       "           0.0729, -0.2821, -0.0809, -0.7085,  0.4104, -0.2980, -0.3305, -0.5970,\n",
       "           0.4380,  0.3960,  0.9885,  0.0977,  0.7679, -0.3356, -0.0649,  0.1464,\n",
       "          -0.5921, -0.9984,  0.3212,  0.8101, -0.0156, -0.5315, -0.0969,  0.6590,\n",
       "          -0.7928, -0.4020,  0.7257, -0.0829, -0.1768,  0.0360,  0.0600,  0.8870,\n",
       "           0.2563,  0.5292,  0.6321,  0.6289,  0.2573, -0.5432, -0.5772,  0.7266]],\n",
       "        grad_fn=<TanhBackward>))"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bertmodel(torch.tensor(w).view(1, -1)).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[7592, 2088]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(w).view(1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'I am Mr. Huderson. Nice to meet you!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'am',\n",
       " 'mr',\n",
       " '.',\n",
       " 'hu',\n",
       " '##ders',\n",
       " '##on',\n",
       " '.',\n",
       " 'nice',\n",
       " 'to',\n",
       " 'meet',\n",
       " 'you',\n",
       " '!']"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tokenizer.convert_tokens_to_ids(tokenizer.tokenize(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): BertLayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bertmodel.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[[ 1.9892e-02,  4.1328e-01, -2.2181e-01,  ...,  2.8706e-01,\n",
       "            2.1810e-01,  1.2246e-01],\n",
       "          [ 2.3839e-01,  1.5515e-01,  3.8293e-02,  ...,  3.2719e-01,\n",
       "            1.8921e+00, -8.7180e-01],\n",
       "          [ 6.5080e-01, -1.2168e-02,  6.3863e-01,  ..., -7.2215e-01,\n",
       "            1.3916e+00,  5.7533e-01],\n",
       "          ...,\n",
       "          [ 3.7708e-02,  1.0109e+00, -4.7395e-01,  ...,  5.1558e-01,\n",
       "           -1.1349e-01,  1.4388e-01],\n",
       "          [-8.0848e-01,  9.0437e-01,  8.1153e-01,  ...,  8.5186e-01,\n",
       "            4.6818e-01,  5.5948e-01],\n",
       "          [ 4.4215e-01,  8.4447e-04, -2.4784e-01,  ...,  4.3650e-01,\n",
       "            5.2623e-01,  8.9815e-01]]], grad_fn=<AddBackward0>),\n",
       " tensor([[[ 0.0931, -0.0026, -0.1744,  ...,  0.3635,  0.3804, -0.3315],\n",
       "          [-0.0346, -0.0546, -0.1009,  ..., -0.0390,  2.1550, -1.1211],\n",
       "          [ 0.7665,  0.3611,  0.6790,  ..., -0.9274,  2.0904,  0.3948],\n",
       "          ...,\n",
       "          [ 0.2872,  1.4756,  0.3939,  ...,  0.0975, -0.2599, -0.4322],\n",
       "          [-0.7783,  0.3017,  0.9420,  ...,  0.6353,  0.5864,  0.3655],\n",
       "          [ 0.3346, -0.1970, -0.2702,  ...,  0.4082,  0.6615,  0.6165]]],\n",
       "        grad_fn=<AddBackward0>),\n",
       " tensor([[[ 0.0761, -0.2491, -0.1021,  ...,  0.3314,  0.3509, -0.2151],\n",
       "          [ 0.0658,  0.4849, -0.1650,  ..., -0.5012,  1.4632, -0.9717],\n",
       "          [ 0.3142, -0.4819,  0.8315,  ..., -0.7064,  1.3585,  0.2844],\n",
       "          ...,\n",
       "          [ 0.8006,  1.2503,  0.8259,  ..., -0.0282, -0.3311, -0.4830],\n",
       "          [-0.5312, -0.0144,  0.9381,  ...,  0.6763,  0.7068,  0.5630],\n",
       "          [ 0.6172, -0.1525, -0.2033,  ..., -0.0563,  0.5177,  0.9901]]],\n",
       "        grad_fn=<AddBackward0>),\n",
       " tensor([[[ 0.3370, -0.5029, -0.7083,  ...,  0.4171,  0.0726,  0.0980],\n",
       "          [ 0.3240,  0.2389,  0.2275,  ..., -0.4990,  0.8288, -0.7471],\n",
       "          [ 0.5689, -1.1243,  0.7469,  ..., -0.7110,  0.8807,  0.6808],\n",
       "          ...,\n",
       "          [ 0.8998,  1.1075,  0.3119,  ..., -0.1231,  0.0753, -0.3702],\n",
       "          [-0.3349, -0.1777,  0.9290,  ...,  0.4330,  0.2373,  0.4969],\n",
       "          [ 0.5446,  0.2881,  0.2669,  ...,  0.1985,  0.2011,  0.9791]]],\n",
       "        grad_fn=<AddBackward0>),\n",
       " tensor([[[ 0.0743, -0.3209, -0.4283,  ...,  0.0244,  0.1288,  0.3687],\n",
       "          [ 0.9158,  0.3800,  1.0112,  ...,  0.0230,  0.7124, -0.4221],\n",
       "          [ 0.5591, -0.3362,  0.6039,  ..., -0.6035,  0.8597,  0.3223],\n",
       "          ...,\n",
       "          [ 0.7898,  1.3071,  0.9616,  ...,  0.2815,  0.0883, -0.2826],\n",
       "          [-0.0127,  0.1215,  1.5828,  ...,  0.9840,  0.7436, -0.0352],\n",
       "          [ 0.7646,  0.7871,  0.8139,  ..., -0.0776, -0.2103,  0.7514]]],\n",
       "        grad_fn=<AddBackward0>),\n",
       " tensor([[[ 0.2407, -0.2779, -0.0786,  ..., -0.5073, -0.7663,  0.2408],\n",
       "          [ 0.6305,  0.3934,  0.9659,  ..., -0.0499,  0.9048, -0.3040],\n",
       "          [ 0.4036, -0.0176,  0.3026,  ..., -0.4161,  0.9047,  0.0091],\n",
       "          ...,\n",
       "          [ 0.6678,  1.2195,  1.7628,  ..., -0.0996,  0.3993, -0.3781],\n",
       "          [-0.0065,  0.4895,  2.0277,  ...,  0.5116,  0.8418, -0.6699],\n",
       "          [ 0.8543,  0.5704,  0.9793,  ..., -0.3301, -0.6717,  0.7180]]],\n",
       "        grad_fn=<AddBackward0>),\n",
       " tensor([[[ 0.1003,  0.2371, -0.2454,  ..., -1.3005, -0.3307,  0.0099],\n",
       "          [ 1.3405,  0.8319,  0.8129,  ..., -0.6847,  0.8756, -0.6514],\n",
       "          [ 0.5119,  0.9185,  0.3826,  ..., -0.4345,  1.1606, -0.3988],\n",
       "          ...,\n",
       "          [ 0.4449,  1.8810,  1.6837,  ...,  0.2203,  1.2527, -0.3052],\n",
       "          [ 0.1445,  0.7691,  2.1240,  ...,  0.6577,  1.5550, -1.0590],\n",
       "          [ 0.5739,  0.3007,  0.5900,  ..., -0.6238, -0.0431,  0.6511]]],\n",
       "        grad_fn=<AddBackward0>),\n",
       " tensor([[[-0.0060,  0.1255,  0.0633,  ..., -0.6696, -0.0816,  0.4857],\n",
       "          [ 0.8446,  1.4677,  1.0486,  ..., -0.7875,  0.9918, -0.0116],\n",
       "          [ 0.2661,  1.0410,  0.5289,  ..., -0.4970,  1.1756, -0.1568],\n",
       "          ...,\n",
       "          [-0.3148,  1.5731,  1.9422,  ...,  0.2259,  1.4715,  0.1313],\n",
       "          [-0.5941,  0.6180,  2.3031,  ...,  0.5227,  1.5218, -0.1626],\n",
       "          [ 0.3937,  0.4621,  1.2952,  ..., -0.0862,  0.3014,  0.6111]]],\n",
       "        grad_fn=<AddBackward0>),\n",
       " tensor([[[ 0.1796, -0.0821,  0.0439,  ..., -0.4205, -0.0157,  0.4956],\n",
       "          [ 0.3703,  1.2399,  0.8551,  ..., -0.7471,  0.3734,  0.1433],\n",
       "          [ 0.0668,  0.8330,  0.1013,  ..., -0.3838,  0.7893,  0.2160],\n",
       "          ...,\n",
       "          [-0.2348,  1.5066,  1.5257,  ..., -0.2900,  0.7548,  0.3234],\n",
       "          [-0.3194,  0.7628,  1.7479,  ...,  0.4834,  1.1719, -0.0649],\n",
       "          [ 0.2338,  0.2301,  0.9826,  ..., -0.1110,  0.0171,  0.5365]]],\n",
       "        grad_fn=<AddBackward0>),\n",
       " tensor([[[ 0.0044, -0.4091,  0.1130,  ..., -0.2413, -0.0090,  0.6163],\n",
       "          [ 0.1546,  0.5277,  1.0395,  ..., -0.6629,  0.1321,  0.2244],\n",
       "          [ 0.0270,  0.3403,  0.3598,  ..., -0.4602,  0.5951,  0.1579],\n",
       "          ...,\n",
       "          [-0.3975,  0.7972,  1.1768,  ..., -0.4285,  0.2103,  0.1191],\n",
       "          [-0.5365,  0.2499,  1.3774,  ...,  0.1109,  0.8292, -0.1584],\n",
       "          [ 0.0201, -0.1292,  0.9398,  ..., -0.1206,  0.0222,  0.3273]]],\n",
       "        grad_fn=<AddBackward0>),\n",
       " tensor([[[-0.4371, -0.2744, -0.4220,  ..., -0.2650,  0.0243,  0.9606],\n",
       "          [-0.4428,  0.7160,  0.8425,  ..., -0.6946,  0.5709,  0.9182],\n",
       "          [-0.3579,  0.7118,  0.0261,  ..., -0.4953,  0.8136,  0.7366],\n",
       "          ...,\n",
       "          [-0.9599,  0.9454,  0.8437,  ..., -0.6053,  0.7125,  0.6841],\n",
       "          [-0.9922,  0.2875,  0.8703,  ...,  0.1237,  1.2764,  0.2653],\n",
       "          [-0.3324, -0.0682,  0.3941,  ..., -0.2055,  0.0916,  0.7045]]],\n",
       "        grad_fn=<AddBackward0>),\n",
       " tensor([[[-0.3265, -0.0941, -0.0293,  ..., -0.2886,  0.2378,  0.8151],\n",
       "          [-0.3457,  0.1342,  0.7511,  ..., -0.4625,  0.4948,  0.8039],\n",
       "          [-0.1487,  0.0965,  0.3460,  ..., -0.3606,  0.4259,  0.6665],\n",
       "          ...,\n",
       "          [-0.5674,  0.2269,  0.8748,  ..., -0.3410,  0.2721,  0.9102],\n",
       "          [-0.5409, -0.1106,  0.7355,  ...,  0.0470,  0.6074,  0.5736],\n",
       "          [-0.2768, -0.1212,  0.4742,  ..., -0.1294,  0.2199,  0.7121]]],\n",
       "        grad_fn=<AddBackward0>)]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out, _ = bertmodel(torch.tensor(x).view(1, -1))\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1045, 2572, 2720, 1012, 15876, 13375, 2239, 1012, 3835, 2000, 3113, 2017, 999]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Who was Jim Henson ? Jim Henson was a puppeteer\"\n",
    "tokenized_text = tokenizer.tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['who',\n",
       " 'was',\n",
       " 'jim',\n",
       " 'henson',\n",
       " '?',\n",
       " 'jim',\n",
       " 'henson',\n",
       " 'was',\n",
       " 'a',\n",
       " 'puppet',\n",
       " '##eer']"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2040, 2001, 3958, 27227, 1029, 3958, 27227, 2001, 1037, 13997, 11510]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "indexed_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_tensor = torch.tensor(indexed_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "Dimension out of range (expected to be in range of [-1, 0], but got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-80-10f78927f53e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Predict hidden states features for each layer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mencoded_layers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtokens_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mencoded_layers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 550\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    551\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\lib\\site-packages\\pytorch_pretrained_bert\\modeling.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input_ids, token_type_ids, attention_mask, output_all_encoded_layers)\u001b[0m\n\u001b[0;32m    728\u001b[0m         \u001b[0mextended_attention_mask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1.0\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mextended_attention_mask\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m10000.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    729\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 730\u001b[1;33m         \u001b[0membedding_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membeddings\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtoken_type_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    731\u001b[0m         encoded_layers = self.encoder(embedding_output,\n\u001b[0;32m    732\u001b[0m                                       \u001b[0mextended_attention_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 550\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    551\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\lib\\site-packages\\pytorch_pretrained_bert\\modeling.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input_ids, token_type_ids)\u001b[0m\n\u001b[0;32m    259\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    260\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtoken_type_ids\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 261\u001b[1;33m         \u001b[0mseq_length\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    262\u001b[0m         \u001b[0mposition_ids\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseq_length\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    263\u001b[0m         \u001b[0mposition_ids\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mposition_ids\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpand_as\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: Dimension out of range (expected to be in range of [-1, 0], but got 1)"
     ]
    }
   ],
   "source": [
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Predict hidden states features for each layer\n",
    "encoded_layers, _ = model(tokens_tensor.view(1, -1))\n",
    "len(encoded_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 11, 768])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_layers[0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our Deeds are the Reason of this #earthquake May ALLAH Forgive us all\n",
      "Forest fire near La Ronge Sask. Canada\n",
      "All residents asked to 'shelter in place' are being notified by officers. No other evacuation or shelter in place orders are expected\n",
      "13,000 people receive #wildfires evacuation orders in California \n",
      "Just got sent this photo from Ruby #Alaska as smoke from #wildfires pours into a school \n"
     ]
    }
   ],
   "source": [
    "for text in df.head().text:\n",
    "    print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [1, 2, 3, 5, 6]\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.shuffle(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 5, 1, 3, 6]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = [2, 4, 6, 8, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2, 2), (5, 4), (1, 6), (3, 8), (6, 1)]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(a, b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
